{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e96f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31a29b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('balanced_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f19086fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tops = data[data['category'] == 'Shirts/Tops']\n",
    "reviews = tops['text'].tolist()\n",
    "ratings = tops['rating'].astype(int).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd689618",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [str(i) for i in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c403bb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'rating', 'parent_asin', 'text', 'title',\n",
       "       'average_rating', 'category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tops.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90dc1641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_model = BERTopic(language=\"english\", verbose=True)\n",
    "#topics, probs = topic_model.fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91dae560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ed8b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd3db01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "topic_model = BERTopic(embedding_model=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "933ea2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_model = CountVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1, 2)   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc130ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topic_model = BERTopic(embedding_model=embedding_model, vectorizer_model=vectorizer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44f8d517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "topics, probs = topic_model.fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2516c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "tops['topic'] = topics\n",
    "tops['topic_probs'] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543e0f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment scores calculated. Range: -1.000 to 1.000\n",
      "Mean sentiment: 0.156\n"
     ]
    }
   ],
   "source": [
    "tops_cleaned = tops[tops['topic'] != -1]\n",
    "\n",
    "# Calculate sentiment polarity for each review\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "\n",
    "# Download required NLTK data (only needed first time)\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "try:\n",
    "    nltk.data.find('taggers/averaged_perceptron_tagger')\n",
    "except LookupError:\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Polarity ranges from -1 (negative) to 1 (positive)\n",
    "sentiment_scores = []\n",
    "for review in tops_cleaned['text']:\n",
    "    blob = TextBlob(str(review))\n",
    "    sentiment_scores.append(blob.sentiment.polarity)\n",
    "\n",
    "tops_cleaned['sentiment_polarity'] = sentiment_scores\n",
    "\n",
    "print(f\"Sentiment scores calculated. Range: {min(sentiment_scores):.3f} to {max(sentiment_scores):.3f}\")\n",
    "print(f\"Mean sentiment: {np.mean(sentiment_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9fdb758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rating</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>category</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_probs</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B08NHJ5S5H</td>\n",
       "      <td>Not long enough. I like shirt that cover or be...</td>\n",
       "      <td>Dokotoo Women's Ladies Spring Basic Ribbed Str...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Shirts/Tops</td>\n",
       "      <td>11</td>\n",
       "      <td>0.987920</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>B071F91SCM</td>\n",
       "      <td>Very pretty, but the post is super thick and t...</td>\n",
       "      <td>925 Sterling Silver Cubic Zirconia Purple Butt...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Shirts/Tops</td>\n",
       "      <td>17</td>\n",
       "      <td>0.234251</td>\n",
       "      <td>0.119444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>B08JGGTCB9</td>\n",
       "      <td>I got it for my bf for his birthday was disapp...</td>\n",
       "      <td>Jordan Paris Saint-Germain Long-Sleeve T-Shirt...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Shirts/Tops</td>\n",
       "      <td>323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>B01IP4GEA2</td>\n",
       "      <td>Small and itchy.</td>\n",
       "      <td>Romwe Women's Striped Crewneck Short Sleeve Lo...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Shirts/Tops</td>\n",
       "      <td>160</td>\n",
       "      <td>0.963756</td>\n",
       "      <td>-0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>B08B5QZYWD</td>\n",
       "      <td>I love this shirt.  It’s soft on my skin and d...</td>\n",
       "      <td>Happy Sailed Womens High Low Swing Pullover Pr...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Shirts/Tops</td>\n",
       "      <td>16</td>\n",
       "      <td>0.589095</td>\n",
       "      <td>0.292857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  rating parent_asin  \\\n",
       "0            0     2.0  B08NHJ5S5H   \n",
       "3            3     3.0  B071F91SCM   \n",
       "9            9     4.0  B08JGGTCB9   \n",
       "17          17     3.0  B01IP4GEA2   \n",
       "18          18     5.0  B08B5QZYWD   \n",
       "\n",
       "                                                 text  \\\n",
       "0   Not long enough. I like shirt that cover or be...   \n",
       "3   Very pretty, but the post is super thick and t...   \n",
       "9   I got it for my bf for his birthday was disapp...   \n",
       "17                                   Small and itchy.   \n",
       "18  I love this shirt.  It’s soft on my skin and d...   \n",
       "\n",
       "                                                title  average_rating  \\\n",
       "0   Dokotoo Women's Ladies Spring Basic Ribbed Str...             3.6   \n",
       "3   925 Sterling Silver Cubic Zirconia Purple Butt...             4.7   \n",
       "9   Jordan Paris Saint-Germain Long-Sleeve T-Shirt...             4.0   \n",
       "17  Romwe Women's Striped Crewneck Short Sleeve Lo...             3.3   \n",
       "18  Happy Sailed Womens High Low Swing Pullover Pr...             3.1   \n",
       "\n",
       "       category  topic  topic_probs  sentiment_polarity  \n",
       "0   Shirts/Tops     11     0.987920            0.012500  \n",
       "3   Shirts/Tops     17     0.234251            0.119444  \n",
       "9   Shirts/Tops    323     1.000000           -0.125000  \n",
       "17  Shirts/Tops    160     0.963756           -0.250000  \n",
       "18  Shirts/Tops     16     0.589095            0.292857  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tops_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe9d6d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [[[VIDEOID:9bc533c84abc87e9f505bb102bba2cf8]] ...\n",
      "Name: Representative_Docs, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#topic_model.get_topic_info(1)['Representative_Docs']\n",
    "\n",
    "print(topic_model.get_topic_info(2)['Representative_Docs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3487858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"These were a cute style, and the material was a pretty print. However, the coverage was a little too full in the back for me. It hit me low on the hip in a weird way.<br /><br />I think the rise was right at or just above my belly button, but it's been a few weeks since I returned these, so I can't remember exactly. I remember the waistband was very comfortable, almost loose, so there was no muffin top or anything like that.<br /><br />I also think I might have needed to size down a size or two. I considered re-ordering, but I wasn't sure about the cut of the back. I still sometimes think about trying to re-order in a smaller size to see if they would look different or better.<br /><br />The lack of a true tummy control lining was a bit of a disappointment. I also don't remember if these were fully lined, front and back. If they were not, that was another factor in the decision to return.<br /><br />However, these could be very cute, and a great buy, for someone who wants this fuller coverage in the rear. The price is very good for this style of bottoms, compared to others offered on Amazon.<br /><br />The return was fast and easy.\",\n",
       " \"First, the order said it wouldn't arrive until the end of September, but, it came early, sometime in August. Upon opening the package I knew immediately that they probably wouldn't fit. But, thinking maybe I wasn't figuring correctly, I tried to don said panties and found that they were only a whisper and a prayer away from fitting. Pretty to look at, but comfort was not key here. I kept them hanging on a small hook to remind me to not buy clothing on a whim and to stop shopping while sleepy. Lovely color, sweet silk fabric could use softer thread in the elastic, but a lot of panties are this way and several washings might have changed that. If I were younger, I'd probably try to squeeze into them once in a while, but now... not so much.  Beautifully made, lovely color, soft fabric but not so soft at the waist because of the elastic which is actually below the belly button.\",\n",
       " \"In fact, after recieving these pants I wish I had checked wish first because I probably would have gotten the same thing only cheaper.. anyway these are very falsely advertised and are NOT cotton. The tag says 95% rayon and 5% spandex. The material is very thin and these pants are definitely low quality. I do however feel like they mostly fit the same way down both both legs and around the body and such and what I do like is the elastic in the ankles - it is loose fitting but hugs enough that the pants don't go too long. That was mostly what I was wanting out of them - comfortable loose lounge pants that wouldn't go past my ankles on my tiny legs. I am only 5 feet tall. As for the fit around the waist if I pull them all the way up they will cover my 24 week pregnant belly easily and comfortably hug around my rib cage below my boobs. But I feel like I can probably also wear them low on my hips comfortably if I want to go MC Hammer style. Can't trust too much on fit though because you obviously can't trust the seller already with material and I ordered small and was sent pants with an M sticker.. so who knows what size they are.  There is no size identifier on the tag. I do wish they were cotton.\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_representative_docs(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64def264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>85</td>\n",
       "      <td>45_pants_legs_pant_leg</td>\n",
       "      <td>[pants, legs, pant, leg, sweatpants, panties, ...</td>\n",
       "      <td>[These were a cute style, and the material was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                    Name  \\\n",
       "0     45     85  45_pants_legs_pant_leg   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [pants, legs, pant, leg, sweatpants, panties, ...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [These were a cute style, and the material was...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a84b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>14838</td>\n",
       "      <td>-1_shirt_size_material_like</td>\n",
       "      <td>[shirt, size, material, like, fit, small, br, ...</td>\n",
       "      <td>[When I normally buy something online I ALWAYS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1726</td>\n",
       "      <td>0_dress_love dress_dresses_cute dress</td>\n",
       "      <td>[dress, love dress, dresses, cute dress, pocke...</td>\n",
       "      <td>[Cute dress but it runs very small, Love this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1023</td>\n",
       "      <td>1_tops_cute_love_beautiful</td>\n",
       "      <td>[tops, cute, love, beautiful, fits, really, ni...</td>\n",
       "      <td>[cute top, Cute top, It is a very cute top]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>414</td>\n",
       "      <td>2_la_muy_es_el</td>\n",
       "      <td>[la, muy, es, el, que, calidad, pero, tela, en...</td>\n",
       "      <td>[[[VIDEOID:9bc533c84abc87e9f505bb102bba2cf8]] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>370</td>\n",
       "      <td>3_blouse_nice blouse_blouses_beautiful blouse</td>\n",
       "      <td>[blouse, nice blouse, blouses, beautiful blous...</td>\n",
       "      <td>[Really like this blouse., cute blouse., Very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>379</td>\n",
       "      <td>10</td>\n",
       "      <td>379_order based_gathers_raise arms_chart ordered</td>\n",
       "      <td>[order based, gathers, raise arms, chart order...</td>\n",
       "      <td>[I have a 36 chest size so I ordered an XL. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>380</td>\n",
       "      <td>10</td>\n",
       "      <td>380_away gave_gave away_away_gave</td>\n",
       "      <td>[away gave, gave away, away, gave, didn givwe,...</td>\n",
       "      <td>[I gave it away, gave it away, I gave it away]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>381</td>\n",
       "      <td>10</td>\n",
       "      <td>381_glue_wow broke_cute playful_like play</td>\n",
       "      <td>[glue, wow broke, cute playful, like play, han...</td>\n",
       "      <td>[Its cute but made with such cheap metal. Feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>382</td>\n",
       "      <td>10</td>\n",
       "      <td>382_wonder 10_clearly slightly_awkward fan_sea...</td>\n",
       "      <td>[wonder 10, clearly slightly, awkward fan, sea...</td>\n",
       "      <td>[very thin material and runs a little small. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>383</td>\n",
       "      <td>10</td>\n",
       "      <td>383_member_pay return_sold_largw</td>\n",
       "      <td>[member, pay return, sold, largw, stroke limit...</td>\n",
       "      <td>[This shirt was Way Too Small, Unless you're a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>385 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                               Name  \\\n",
       "0       -1  14838                        -1_shirt_size_material_like   \n",
       "1        0   1726              0_dress_love dress_dresses_cute dress   \n",
       "2        1   1023                         1_tops_cute_love_beautiful   \n",
       "3        2    414                                     2_la_muy_es_el   \n",
       "4        3    370      3_blouse_nice blouse_blouses_beautiful blouse   \n",
       "..     ...    ...                                                ...   \n",
       "380    379     10   379_order based_gathers_raise arms_chart ordered   \n",
       "381    380     10                  380_away gave_gave away_away_gave   \n",
       "382    381     10          381_glue_wow broke_cute playful_like play   \n",
       "383    382     10  382_wonder 10_clearly slightly_awkward fan_sea...   \n",
       "384    383     10                   383_member_pay return_sold_largw   \n",
       "\n",
       "                                        Representation  \\\n",
       "0    [shirt, size, material, like, fit, small, br, ...   \n",
       "1    [dress, love dress, dresses, cute dress, pocke...   \n",
       "2    [tops, cute, love, beautiful, fits, really, ni...   \n",
       "3    [la, muy, es, el, que, calidad, pero, tela, en...   \n",
       "4    [blouse, nice blouse, blouses, beautiful blous...   \n",
       "..                                                 ...   \n",
       "380  [order based, gathers, raise arms, chart order...   \n",
       "381  [away gave, gave away, away, gave, didn givwe,...   \n",
       "382  [glue, wow broke, cute playful, like play, han...   \n",
       "383  [wonder 10, clearly slightly, awkward fan, sea...   \n",
       "384  [member, pay return, sold, largw, stroke limit...   \n",
       "\n",
       "                                   Representative_Docs  \n",
       "0    [When I normally buy something online I ALWAYS...  \n",
       "1    [Cute dress but it runs very small, Love this ...  \n",
       "2          [cute top, Cute top, It is a very cute top]  \n",
       "3    [[[VIDEOID:9bc533c84abc87e9f505bb102bba2cf8]] ...  \n",
       "4    [Really like this blouse., cute blouse., Very ...  \n",
       "..                                                 ...  \n",
       "380  [I have a 36 chest size so I ordered an XL. It...  \n",
       "381     [I gave it away, gave it away, I gave it away]  \n",
       "382  [Its cute but made with such cheap metal. Feel...  \n",
       "383  [very thin material and runs a little small. I...  \n",
       "384  [This shirt was Way Too Small, Unless you're a...  \n",
       "\n",
       "[385 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "640d9830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic info before removing outliers:\n",
      "     Topic  Count                                               Name  \\\n",
      "0       -1  14838                        -1_shirt_size_material_like   \n",
      "1        0   1726              0_dress_love dress_dresses_cute dress   \n",
      "2        1   1023                         1_tops_cute_love_beautiful   \n",
      "3        2    414                                     2_la_muy_es_el   \n",
      "4        3    370      3_blouse_nice blouse_blouses_beautiful blouse   \n",
      "..     ...    ...                                                ...   \n",
      "380    379     10   379_order based_gathers_raise arms_chart ordered   \n",
      "381    380     10                  380_away gave_gave away_away_gave   \n",
      "382    381     10          381_glue_wow broke_cute playful_like play   \n",
      "383    382     10  382_wonder 10_clearly slightly_awkward fan_sea...   \n",
      "384    383     10                   383_member_pay return_sold_largw   \n",
      "\n",
      "                                        Representation  \\\n",
      "0    [shirt, size, material, like, fit, small, br, ...   \n",
      "1    [dress, love dress, dresses, cute dress, pocke...   \n",
      "2    [tops, cute, love, beautiful, fits, really, ni...   \n",
      "3    [la, muy, es, el, que, calidad, pero, tela, en...   \n",
      "4    [blouse, nice blouse, blouses, beautiful blous...   \n",
      "..                                                 ...   \n",
      "380  [order based, gathers, raise arms, chart order...   \n",
      "381  [away gave, gave away, away, gave, didn givwe,...   \n",
      "382  [glue, wow broke, cute playful, like play, han...   \n",
      "383  [wonder 10, clearly slightly, awkward fan, sea...   \n",
      "384  [member, pay return, sold, largw, stroke limit...   \n",
      "\n",
      "                                   Representative_Docs  \n",
      "0    [When I normally buy something online I ALWAYS...  \n",
      "1    [Cute dress but it runs very small, Love this ...  \n",
      "2          [cute top, Cute top, It is a very cute top]  \n",
      "3    [[[VIDEOID:9bc533c84abc87e9f505bb102bba2cf8]] ...  \n",
      "4    [Really like this blouse., cute blouse., Very ...  \n",
      "..                                                 ...  \n",
      "380  [I have a 36 chest size so I ordered an XL. It...  \n",
      "381     [I gave it away, gave it away, I gave it away]  \n",
      "382  [Its cute but made with such cheap metal. Feel...  \n",
      "383  [very thin material and runs a little small. I...  \n",
      "384  [This shirt was Way Too Small, Unless you're a...  \n",
      "\n",
      "[385 rows x 5 columns]\n",
      "\n",
      "Total topics including outliers: 385\n",
      "\n",
      "Topic info after removing outliers (topic = -1):\n",
      "     Topic  Count                                               Name  \\\n",
      "1        0   1726              0_dress_love dress_dresses_cute dress   \n",
      "2        1   1023                         1_tops_cute_love_beautiful   \n",
      "3        2    414                                     2_la_muy_es_el   \n",
      "4        3    370      3_blouse_nice blouse_blouses_beautiful blouse   \n",
      "5        4    300               4_suit_bathing_swimsuit_bathing suit   \n",
      "..     ...    ...                                                ...   \n",
      "380    379     10   379_order based_gathers_raise arms_chart ordered   \n",
      "381    380     10                  380_away gave_gave away_away_gave   \n",
      "382    381     10          381_glue_wow broke_cute playful_like play   \n",
      "383    382     10  382_wonder 10_clearly slightly_awkward fan_sea...   \n",
      "384    383     10                   383_member_pay return_sold_largw   \n",
      "\n",
      "                                        Representation  \\\n",
      "1    [dress, love dress, dresses, cute dress, pocke...   \n",
      "2    [tops, cute, love, beautiful, fits, really, ni...   \n",
      "3    [la, muy, es, el, que, calidad, pero, tela, en...   \n",
      "4    [blouse, nice blouse, blouses, beautiful blous...   \n",
      "5    [suit, bathing, swimsuit, bathing suit, bottom...   \n",
      "..                                                 ...   \n",
      "380  [order based, gathers, raise arms, chart order...   \n",
      "381  [away gave, gave away, away, gave, didn givwe,...   \n",
      "382  [glue, wow broke, cute playful, like play, han...   \n",
      "383  [wonder 10, clearly slightly, awkward fan, sea...   \n",
      "384  [member, pay return, sold, largw, stroke limit...   \n",
      "\n",
      "                                   Representative_Docs  \n",
      "1    [Cute dress but it runs very small, Love this ...  \n",
      "2          [cute top, Cute top, It is a very cute top]  \n",
      "3    [[[VIDEOID:9bc533c84abc87e9f505bb102bba2cf8]] ...  \n",
      "4    [Really like this blouse., cute blouse., Very ...  \n",
      "5    [Cute bathing suit but material was a little t...  \n",
      "..                                                 ...  \n",
      "380  [I have a 36 chest size so I ordered an XL. It...  \n",
      "381     [I gave it away, gave it away, I gave it away]  \n",
      "382  [Its cute but made with such cheap metal. Feel...  \n",
      "383  [very thin material and runs a little small. I...  \n",
      "384  [This shirt was Way Too Small, Unless you're a...  \n",
      "\n",
      "[384 rows x 5 columns]\n",
      "\n",
      "Total topics after removing outliers: 384\n"
     ]
    }
   ],
   "source": [
    "# Get topic info and remove topic = -1 (outliers)\n",
    "topic_info = topic_model.get_topic_info()\n",
    "print(\"Topic info before removing outliers:\")\n",
    "print(topic_info)\n",
    "print(f\"\\nTotal topics including outliers: {len(topic_info)}\")\n",
    "\n",
    "# Remove topic = -1 from topic info\n",
    "topic_info_cleaned = topic_info[topic_info['Topic'] != -1].copy()\n",
    "print(f\"\\nTopic info after removing outliers (topic = -1):\")\n",
    "print(topic_info_cleaned)\n",
    "print(f\"\\nTotal topics after removing outliers: {len(topic_info_cleaned)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a39c6701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1726</td>\n",
       "      <td>0_dress_love dress_dresses_cute dress</td>\n",
       "      <td>[dress, love dress, dresses, cute dress, pocke...</td>\n",
       "      <td>[Cute dress but it runs very small, Love this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1023</td>\n",
       "      <td>1_tops_cute_love_beautiful</td>\n",
       "      <td>[tops, cute, love, beautiful, fits, really, ni...</td>\n",
       "      <td>[cute top, Cute top, It is a very cute top]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>414</td>\n",
       "      <td>2_la_muy_es_el</td>\n",
       "      <td>[la, muy, es, el, que, calidad, pero, tela, en...</td>\n",
       "      <td>[[[VIDEOID:9bc533c84abc87e9f505bb102bba2cf8]] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>370</td>\n",
       "      <td>3_blouse_nice blouse_blouses_beautiful blouse</td>\n",
       "      <td>[blouse, nice blouse, blouses, beautiful blous...</td>\n",
       "      <td>[Really like this blouse., cute blouse., Very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>4_suit_bathing_swimsuit_bathing suit</td>\n",
       "      <td>[suit, bathing, swimsuit, bathing suit, bottom...</td>\n",
       "      <td>[Cute bathing suit but material was a little t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>379</td>\n",
       "      <td>10</td>\n",
       "      <td>379_order based_gathers_raise arms_chart ordered</td>\n",
       "      <td>[order based, gathers, raise arms, chart order...</td>\n",
       "      <td>[I have a 36 chest size so I ordered an XL. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>380</td>\n",
       "      <td>10</td>\n",
       "      <td>380_away gave_gave away_away_gave</td>\n",
       "      <td>[away gave, gave away, away, gave, didn givwe,...</td>\n",
       "      <td>[I gave it away, gave it away, I gave it away]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>381</td>\n",
       "      <td>10</td>\n",
       "      <td>381_glue_wow broke_cute playful_like play</td>\n",
       "      <td>[glue, wow broke, cute playful, like play, han...</td>\n",
       "      <td>[Its cute but made with such cheap metal. Feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>382</td>\n",
       "      <td>10</td>\n",
       "      <td>382_wonder 10_clearly slightly_awkward fan_sea...</td>\n",
       "      <td>[wonder 10, clearly slightly, awkward fan, sea...</td>\n",
       "      <td>[very thin material and runs a little small. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>383</td>\n",
       "      <td>10</td>\n",
       "      <td>383_member_pay return_sold_largw</td>\n",
       "      <td>[member, pay return, sold, largw, stroke limit...</td>\n",
       "      <td>[This shirt was Way Too Small, Unless you're a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                               Name  \\\n",
       "1        0   1726              0_dress_love dress_dresses_cute dress   \n",
       "2        1   1023                         1_tops_cute_love_beautiful   \n",
       "3        2    414                                     2_la_muy_es_el   \n",
       "4        3    370      3_blouse_nice blouse_blouses_beautiful blouse   \n",
       "5        4    300               4_suit_bathing_swimsuit_bathing suit   \n",
       "..     ...    ...                                                ...   \n",
       "380    379     10   379_order based_gathers_raise arms_chart ordered   \n",
       "381    380     10                  380_away gave_gave away_away_gave   \n",
       "382    381     10          381_glue_wow broke_cute playful_like play   \n",
       "383    382     10  382_wonder 10_clearly slightly_awkward fan_sea...   \n",
       "384    383     10                   383_member_pay return_sold_largw   \n",
       "\n",
       "                                        Representation  \\\n",
       "1    [dress, love dress, dresses, cute dress, pocke...   \n",
       "2    [tops, cute, love, beautiful, fits, really, ni...   \n",
       "3    [la, muy, es, el, que, calidad, pero, tela, en...   \n",
       "4    [blouse, nice blouse, blouses, beautiful blous...   \n",
       "5    [suit, bathing, swimsuit, bathing suit, bottom...   \n",
       "..                                                 ...   \n",
       "380  [order based, gathers, raise arms, chart order...   \n",
       "381  [away gave, gave away, away, gave, didn givwe,...   \n",
       "382  [glue, wow broke, cute playful, like play, han...   \n",
       "383  [wonder 10, clearly slightly, awkward fan, sea...   \n",
       "384  [member, pay return, sold, largw, stroke limit...   \n",
       "\n",
       "                                   Representative_Docs  \n",
       "1    [Cute dress but it runs very small, Love this ...  \n",
       "2          [cute top, Cute top, It is a very cute top]  \n",
       "3    [[[VIDEOID:9bc533c84abc87e9f505bb102bba2cf8]] ...  \n",
       "4    [Really like this blouse., cute blouse., Very ...  \n",
       "5    [Cute bathing suit but material was a little t...  \n",
       "..                                                 ...  \n",
       "380  [I have a 36 chest size so I ordered an XL. It...  \n",
       "381     [I gave it away, gave it away, I gave it away]  \n",
       "382  [Its cute but made with such cheap metal. Feel...  \n",
       "383  [very thin material and runs a little small. I...  \n",
       "384  [This shirt was Way Too Small, Unless you're a...  \n",
       "\n",
       "[384 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display cleaned topic info (without topic = -1)\n",
    "topic_info_cleaned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157e76dd",
   "metadata": {},
   "source": [
    "#### Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7842c88e",
   "metadata": {},
   "source": [
    "##### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85c857d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (19095, 2)\n",
      "  - Topic probabilities: 1 features\n",
      "  - Sentiment polarity: 1 feature\n",
      "MSE: 1.353701263781489\n",
      "R-squared: 0.3138095442810107\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Convert topic_probs Series to a 2D numpy array\n",
    "topic_features = np.vstack(tops_cleaned['topic_probs'].values)\n",
    "\n",
    "# Add sentiment polarity as an additional feature\n",
    "sentiment_features = tops_cleaned['sentiment_polarity'].values.reshape(-1, 1)\n",
    "\n",
    "# Combine topic probabilities with sentiment features\n",
    "combined_features = np.hstack([topic_features, sentiment_features])\n",
    "\n",
    "print(f\"Feature shape: {combined_features.shape}\")\n",
    "print(f\"  - Topic probabilities: {topic_features.shape[1]} features\")\n",
    "print(f\"  - Sentiment polarity: 1 feature\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    combined_features, tops_cleaned['rating'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_model = r2_score(y_test, preds)\n",
    "print (\"R-squared:\", r2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24958952",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c15a729b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Performance:\n",
      "MSE: 1.3325\n",
      "RMSE: 1.1543\n",
      "R² Score: 0.3246\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "xgb_preds = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "xgb_mse = mean_squared_error(y_test, xgb_preds)\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "xgb_r2 = r2_score(y_test, xgb_preds)\n",
    "\n",
    "print(\"XGBoost Model Performance:\")\n",
    "print(f\"MSE: {xgb_mse:.4f}\")\n",
    "print(f\"RMSE: {xgb_rmse:.4f}\")\n",
    "print(f\"R² Score: {xgb_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28acd30",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8647e937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.353701263781489\n",
      "R-squared: 0.3138095442810107\n"
     ]
    }
   ],
   "source": [
    "#X = topic_info_cleaned.iloc[:, 2:] #topic probs and sentiment score\n",
    "#y = topic_info_cleaned['rating']\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, tops_cleaned['rating'], test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "r2 = r2_score(y_test, preds)\n",
    "print(f\"R-squared: {r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
