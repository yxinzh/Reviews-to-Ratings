{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1e96f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c07b18f",
   "metadata": {},
   "source": [
    "#### Cleaning Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "31a29b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('balanced_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f19086fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tops = data[data['category'] == 'Shirts/Tops']\n",
    "\n",
    "tops['text'] = tops['text'].str.strip()\n",
    "tops = tops[tops['text'].str.split().str.len() >= 3]  # remove very short reviews\n",
    "bad_values = {\"na\", \"n a\", \"n/a\", \"none\", \"\"}\n",
    "tops = tops[~tops['text'].isin([\"na\", \"n a\", \"n/a\", \"none\", \"\"])] #remove bad values\n",
    "\n",
    "\n",
    "reviews = tops['text'].tolist()\n",
    "ratings = tops['rating'].astype(int).tolist()\n",
    "\n",
    "reviews = [r for r in reviews if r.lower() not in bad_values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cd689618",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [str(i) for i in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d27a8b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)  # remove links\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)         # remove punctuation\n",
    "    text = re.sub(r\"\\d+\", \"\", text)             # remove numbers\n",
    "    text = text.encode(\"ascii\", \"ignore\").decode()  # remove emojis\n",
    "    return text\n",
    "\n",
    "reviews = [clean_text(r) for r in reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc245c98",
   "metadata": {},
   "source": [
    "#### Topic Modeling with BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "896e85b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_model = CountVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    min_df=20,            \n",
    "    max_df=0.8,           \n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "90dc1641",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    calculate_probabilities=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b0472bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 16:31:19,527 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dabd5ad815c441ea89135abf6def7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 16:34:17,335 - BERTopic - Embedding - Completed ✓\n",
      "2025-11-23 16:34:17,338 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-11-23 16:34:26,666 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-11-23 16:34:26,681 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-11-23 16:39:35,991 - BERTopic - Cluster - Completed ✓\n",
      "2025-11-23 16:39:36,016 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-11-23 16:39:38,736 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "topics, probs = topic_model.fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a5d75a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 16:39:41,782 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2025-11-23 16:39:42,004 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-11-23 16:39:44,027 - BERTopic - Representation - Completed ✓\n",
      "2025-11-23 16:39:44,036 - BERTopic - Topic reduction - Reduced number of topics from 331 to 30\n"
     ]
    }
   ],
   "source": [
    "topic_model = topic_model.reduce_topics(reviews, nr_topics=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c5e7e7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9d522e254a495f9c327bd9f31812a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 16:42:36,285 - BERTopic - Dimensionality - Reducing dimensionality of input embeddings.\n",
      "2025-11-23 16:42:36,397 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-11-23 16:42:36,397 - BERTopic - Clustering - Approximating new points with `hdbscan_model`\n",
      "2025-11-23 16:42:37,517 - BERTopic - Probabilities - Start calculation of probabilities with HDBSCAN\n",
      "2025-11-23 16:45:07,157 - BERTopic - Probabilities - Completed ✓\n",
      "2025-11-23 16:45:07,157 - BERTopic - Cluster - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "topics, probs = topic_model.transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "37460357",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (32032) does not match length of index (34082)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[132], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tops[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m topics\n\u001b[0;32m      2\u001b[0m tops[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic_probs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m probs\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32mc:\\Users\\yzhen\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 4311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item(key, value)\n",
      "File \u001b[1;32mc:\\Users\\yzhen\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4524\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4516\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4517\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4522\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4524\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_column(value)\n\u001b[0;32m   4526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4527\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4529\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m   4530\u001b[0m     ):\n\u001b[0;32m   4531\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32mc:\\Users\\yzhen\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5266\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   5263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 5266\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   5267\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   5268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5269\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[0;32m   5270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5273\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[0;32m   5274\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yzhen\\anaconda3\\Lib\\site-packages\\pandas\\core\\common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (32032) does not match length of index (34082)"
     ]
    }
   ],
   "source": [
    "tops['topic'] = topics\n",
    "tops['topic_probs'] = probs.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b521a0d",
   "metadata": {},
   "source": [
    "#### Add Sentiment Score with VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802eb0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\yzhen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bfa6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tops['sentiment'] = tops['text'].apply(lambda x: sia.polarity_scores(str(x))[\"compound\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7218c4cd",
   "metadata": {},
   "source": [
    "#### Creating DataFrame with Probability Distribution for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548e7e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['rating'] = tops['rating']\n",
    "df['topic_id'] = topics\n",
    "df['sentiment'] = tops['sentiment']\n",
    "\n",
    "probs_df = pd.DataFrame(\n",
    "    probs,\n",
    "    columns = [f\"topic_prob_{i}\" for i in range(probs.shape[1])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fee8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>topic_prob_0</th>\n",
       "      <th>topic_prob_1</th>\n",
       "      <th>topic_prob_2</th>\n",
       "      <th>topic_prob_3</th>\n",
       "      <th>topic_prob_4</th>\n",
       "      <th>topic_prob_5</th>\n",
       "      <th>topic_prob_6</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_prob_19</th>\n",
       "      <th>topic_prob_20</th>\n",
       "      <th>topic_prob_21</th>\n",
       "      <th>topic_prob_22</th>\n",
       "      <th>topic_prob_23</th>\n",
       "      <th>topic_prob_24</th>\n",
       "      <th>topic_prob_25</th>\n",
       "      <th>topic_prob_26</th>\n",
       "      <th>topic_prob_27</th>\n",
       "      <th>topic_prob_28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.6918</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8357</td>\n",
       "      <td>1.407189e-01</td>\n",
       "      <td>8.188058e-02</td>\n",
       "      <td>2.226152e-02</td>\n",
       "      <td>1.450290e-02</td>\n",
       "      <td>1.747066e-02</td>\n",
       "      <td>9.261023e-03</td>\n",
       "      <td>4.040478e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.242651e-03</td>\n",
       "      <td>1.977243e-03</td>\n",
       "      <td>7.956023e-04</td>\n",
       "      <td>8.253871e-04</td>\n",
       "      <td>3.012792e-04</td>\n",
       "      <td>5.731639e-04</td>\n",
       "      <td>2.557884e-04</td>\n",
       "      <td>4.783740e-04</td>\n",
       "      <td>6.327596e-04</td>\n",
       "      <td>1.348677e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>5.938534e-01</td>\n",
       "      <td>5.307139e-02</td>\n",
       "      <td>9.089929e-129</td>\n",
       "      <td>5.536364e-129</td>\n",
       "      <td>1.629798e-02</td>\n",
       "      <td>1.386644e-129</td>\n",
       "      <td>4.936046e-130</td>\n",
       "      <td>...</td>\n",
       "      <td>5.785402e-130</td>\n",
       "      <td>3.532178e-130</td>\n",
       "      <td>1.339967e-130</td>\n",
       "      <td>1.383894e-130</td>\n",
       "      <td>2.658912e-131</td>\n",
       "      <td>5.621593e-131</td>\n",
       "      <td>2.418055e-131</td>\n",
       "      <td>3.977161e-131</td>\n",
       "      <td>1.159283e-130</td>\n",
       "      <td>1.425331e-130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.8079</td>\n",
       "      <td>1.589250e-09</td>\n",
       "      <td>6.833651e-10</td>\n",
       "      <td>2.607126e-10</td>\n",
       "      <td>2.866307e-10</td>\n",
       "      <td>1.906143e-10</td>\n",
       "      <td>9.216001e-01</td>\n",
       "      <td>8.747127e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>2.242550e-10</td>\n",
       "      <td>9.370864e-11</td>\n",
       "      <td>2.350942e-11</td>\n",
       "      <td>1.147031e-11</td>\n",
       "      <td>5.396873e-12</td>\n",
       "      <td>1.180296e-11</td>\n",
       "      <td>3.979662e-12</td>\n",
       "      <td>8.465927e-12</td>\n",
       "      <td>2.193662e-11</td>\n",
       "      <td>1.530323e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34077</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.320462e-01</td>\n",
       "      <td>1.771362e-02</td>\n",
       "      <td>6.868606e-03</td>\n",
       "      <td>5.126198e-03</td>\n",
       "      <td>5.285674e-03</td>\n",
       "      <td>3.002853e-03</td>\n",
       "      <td>1.734204e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.165273e-03</td>\n",
       "      <td>7.011363e-04</td>\n",
       "      <td>2.889388e-04</td>\n",
       "      <td>3.775342e-04</td>\n",
       "      <td>1.332665e-04</td>\n",
       "      <td>2.167131e-04</td>\n",
       "      <td>1.260888e-04</td>\n",
       "      <td>1.758986e-04</td>\n",
       "      <td>2.284043e-04</td>\n",
       "      <td>2.967454e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34078</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.4588</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34079</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.033152e-02</td>\n",
       "      <td>3.944086e-02</td>\n",
       "      <td>1.609102e-02</td>\n",
       "      <td>1.304207e-02</td>\n",
       "      <td>1.068483e-02</td>\n",
       "      <td>2.149892e-02</td>\n",
       "      <td>5.759583e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>6.247752e-03</td>\n",
       "      <td>3.470283e-03</td>\n",
       "      <td>9.628476e-04</td>\n",
       "      <td>6.650818e-04</td>\n",
       "      <td>4.172307e-04</td>\n",
       "      <td>7.998477e-04</td>\n",
       "      <td>3.188832e-04</td>\n",
       "      <td>6.576810e-04</td>\n",
       "      <td>1.122466e-03</td>\n",
       "      <td>8.797068e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34080</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>6.755078e-01</td>\n",
       "      <td>9.693865e-03</td>\n",
       "      <td>3.593326e-03</td>\n",
       "      <td>2.485474e-03</td>\n",
       "      <td>2.695232e-03</td>\n",
       "      <td>1.664804e-03</td>\n",
       "      <td>1.136906e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>6.262553e-04</td>\n",
       "      <td>3.779877e-04</td>\n",
       "      <td>1.508980e-04</td>\n",
       "      <td>2.013908e-04</td>\n",
       "      <td>9.219208e-05</td>\n",
       "      <td>1.429136e-04</td>\n",
       "      <td>9.088718e-05</td>\n",
       "      <td>1.325760e-04</td>\n",
       "      <td>1.257210e-04</td>\n",
       "      <td>1.701701e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34081</th>\n",
       "      <td>3.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>9.375952e-02</td>\n",
       "      <td>3.673904e-02</td>\n",
       "      <td>1.820126e-02</td>\n",
       "      <td>1.435631e-02</td>\n",
       "      <td>1.033300e-02</td>\n",
       "      <td>1.439382e-02</td>\n",
       "      <td>8.372131e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.857429e-02</td>\n",
       "      <td>5.303981e-03</td>\n",
       "      <td>9.482998e-04</td>\n",
       "      <td>6.789687e-04</td>\n",
       "      <td>5.971529e-04</td>\n",
       "      <td>8.714197e-04</td>\n",
       "      <td>4.025079e-04</td>\n",
       "      <td>7.018386e-04</td>\n",
       "      <td>1.365523e-03</td>\n",
       "      <td>7.897477e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34082 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating  topic_id  sentiment  topic_prob_0  topic_prob_1   topic_prob_2  \\\n",
       "0         4.0         9     0.6918  0.000000e+00  0.000000e+00   0.000000e+00   \n",
       "1         5.0         1     0.8357  1.407189e-01  8.188058e-02   2.226152e-02   \n",
       "2         3.0        -1     0.0129  5.938534e-01  5.307139e-02  9.089929e-129   \n",
       "3         1.0        16     0.4215  0.000000e+00  0.000000e+00   0.000000e+00   \n",
       "4         1.0         5    -0.8079  1.589250e-09  6.833651e-10   2.607126e-10   \n",
       "...       ...       ...        ...           ...           ...            ...   \n",
       "34077     3.0         0     0.0000  9.320462e-01  1.771362e-02   6.868606e-03   \n",
       "34078     1.0         1    -0.4588  0.000000e+00  1.000000e+00   0.000000e+00   \n",
       "34079     1.0        14     0.0000  9.033152e-02  3.944086e-02   1.609102e-02   \n",
       "34080     1.0         0    -0.4215  6.755078e-01  9.693865e-03   3.593326e-03   \n",
       "34081     3.0        19     0.4215  9.375952e-02  3.673904e-02   1.820126e-02   \n",
       "\n",
       "        topic_prob_3  topic_prob_4   topic_prob_5   topic_prob_6  ...  \\\n",
       "0       0.000000e+00  0.000000e+00   0.000000e+00   0.000000e+00  ...   \n",
       "1       1.450290e-02  1.747066e-02   9.261023e-03   4.040478e-03  ...   \n",
       "2      5.536364e-129  1.629798e-02  1.386644e-129  4.936046e-130  ...   \n",
       "3       0.000000e+00  0.000000e+00   0.000000e+00   0.000000e+00  ...   \n",
       "4       2.866307e-10  1.906143e-10   9.216001e-01   8.747127e-11  ...   \n",
       "...              ...           ...            ...            ...  ...   \n",
       "34077   5.126198e-03  5.285674e-03   3.002853e-03   1.734204e-03  ...   \n",
       "34078   0.000000e+00  0.000000e+00   0.000000e+00   0.000000e+00  ...   \n",
       "34079   1.304207e-02  1.068483e-02   2.149892e-02   5.759583e-03  ...   \n",
       "34080   2.485474e-03  2.695232e-03   1.664804e-03   1.136906e-03  ...   \n",
       "34081   1.435631e-02  1.033300e-02   1.439382e-02   8.372131e-03  ...   \n",
       "\n",
       "       topic_prob_19  topic_prob_20  topic_prob_21  topic_prob_22  \\\n",
       "0       0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "1       3.242651e-03   1.977243e-03   7.956023e-04   8.253871e-04   \n",
       "2      5.785402e-130  3.532178e-130  1.339967e-130  1.383894e-130   \n",
       "3       0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "4       2.242550e-10   9.370864e-11   2.350942e-11   1.147031e-11   \n",
       "...              ...            ...            ...            ...   \n",
       "34077   1.165273e-03   7.011363e-04   2.889388e-04   3.775342e-04   \n",
       "34078   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "34079   6.247752e-03   3.470283e-03   9.628476e-04   6.650818e-04   \n",
       "34080   6.262553e-04   3.779877e-04   1.508980e-04   2.013908e-04   \n",
       "34081   3.857429e-02   5.303981e-03   9.482998e-04   6.789687e-04   \n",
       "\n",
       "       topic_prob_23  topic_prob_24  topic_prob_25  topic_prob_26  \\\n",
       "0       0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "1       3.012792e-04   5.731639e-04   2.557884e-04   4.783740e-04   \n",
       "2      2.658912e-131  5.621593e-131  2.418055e-131  3.977161e-131   \n",
       "3       0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "4       5.396873e-12   1.180296e-11   3.979662e-12   8.465927e-12   \n",
       "...              ...            ...            ...            ...   \n",
       "34077   1.332665e-04   2.167131e-04   1.260888e-04   1.758986e-04   \n",
       "34078   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "34079   4.172307e-04   7.998477e-04   3.188832e-04   6.576810e-04   \n",
       "34080   9.219208e-05   1.429136e-04   9.088718e-05   1.325760e-04   \n",
       "34081   5.971529e-04   8.714197e-04   4.025079e-04   7.018386e-04   \n",
       "\n",
       "       topic_prob_27  topic_prob_28  \n",
       "0       0.000000e+00   0.000000e+00  \n",
       "1       6.327596e-04   1.348677e-03  \n",
       "2      1.159283e-130  1.425331e-130  \n",
       "3       0.000000e+00   0.000000e+00  \n",
       "4       2.193662e-11   1.530323e-11  \n",
       "...              ...            ...  \n",
       "34077   2.284043e-04   2.967454e-04  \n",
       "34078   0.000000e+00   0.000000e+00  \n",
       "34079   1.122466e-03   8.797068e-04  \n",
       "34080   1.257210e-04   1.701701e-04  \n",
       "34081   1.365523e-03   7.897477e-04  \n",
       "\n",
       "[34082 rows x 32 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_prob = pd.concat([df.reset_index(drop=True), probs_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "topic_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05abbe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove topic = -1 because those are outliers and should be ignored\n",
    "model_df = topic_prob[topic_prob['topic_id'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0d3230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>topic_prob_0</th>\n",
       "      <th>topic_prob_1</th>\n",
       "      <th>topic_prob_2</th>\n",
       "      <th>topic_prob_3</th>\n",
       "      <th>topic_prob_4</th>\n",
       "      <th>topic_prob_5</th>\n",
       "      <th>topic_prob_6</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_prob_19</th>\n",
       "      <th>topic_prob_20</th>\n",
       "      <th>topic_prob_21</th>\n",
       "      <th>topic_prob_22</th>\n",
       "      <th>topic_prob_23</th>\n",
       "      <th>topic_prob_24</th>\n",
       "      <th>topic_prob_25</th>\n",
       "      <th>topic_prob_26</th>\n",
       "      <th>topic_prob_27</th>\n",
       "      <th>topic_prob_28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.6918</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8357</td>\n",
       "      <td>1.407189e-01</td>\n",
       "      <td>8.188058e-02</td>\n",
       "      <td>2.226152e-02</td>\n",
       "      <td>1.450290e-02</td>\n",
       "      <td>1.747066e-02</td>\n",
       "      <td>9.261023e-03</td>\n",
       "      <td>4.040478e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.242651e-03</td>\n",
       "      <td>1.977243e-03</td>\n",
       "      <td>7.956023e-04</td>\n",
       "      <td>8.253871e-04</td>\n",
       "      <td>3.012792e-04</td>\n",
       "      <td>5.731639e-04</td>\n",
       "      <td>2.557884e-04</td>\n",
       "      <td>4.783740e-04</td>\n",
       "      <td>6.327596e-04</td>\n",
       "      <td>1.348677e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.8079</td>\n",
       "      <td>1.589250e-09</td>\n",
       "      <td>6.833651e-10</td>\n",
       "      <td>2.607126e-10</td>\n",
       "      <td>2.866307e-10</td>\n",
       "      <td>1.906143e-10</td>\n",
       "      <td>9.216001e-01</td>\n",
       "      <td>8.747127e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>2.242550e-10</td>\n",
       "      <td>9.370864e-11</td>\n",
       "      <td>2.350942e-11</td>\n",
       "      <td>1.147031e-11</td>\n",
       "      <td>5.396873e-12</td>\n",
       "      <td>1.180296e-11</td>\n",
       "      <td>3.979662e-12</td>\n",
       "      <td>8.465927e-12</td>\n",
       "      <td>2.193662e-11</td>\n",
       "      <td>1.530323e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>9.524698e-01</td>\n",
       "      <td>3.504301e-16</td>\n",
       "      <td>3.650877e-17</td>\n",
       "      <td>2.437965e-17</td>\n",
       "      <td>6.270424e-17</td>\n",
       "      <td>1.292472e-17</td>\n",
       "      <td>6.621524e-18</td>\n",
       "      <td>...</td>\n",
       "      <td>5.188340e-18</td>\n",
       "      <td>3.170885e-18</td>\n",
       "      <td>1.203477e-18</td>\n",
       "      <td>1.355813e-18</td>\n",
       "      <td>4.641004e-19</td>\n",
       "      <td>8.230099e-19</td>\n",
       "      <td>4.265775e-19</td>\n",
       "      <td>6.832141e-19</td>\n",
       "      <td>1.038787e-18</td>\n",
       "      <td>1.314411e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34077</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.320462e-01</td>\n",
       "      <td>1.771362e-02</td>\n",
       "      <td>6.868606e-03</td>\n",
       "      <td>5.126198e-03</td>\n",
       "      <td>5.285674e-03</td>\n",
       "      <td>3.002853e-03</td>\n",
       "      <td>1.734204e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.165273e-03</td>\n",
       "      <td>7.011363e-04</td>\n",
       "      <td>2.889388e-04</td>\n",
       "      <td>3.775342e-04</td>\n",
       "      <td>1.332665e-04</td>\n",
       "      <td>2.167131e-04</td>\n",
       "      <td>1.260888e-04</td>\n",
       "      <td>1.758986e-04</td>\n",
       "      <td>2.284043e-04</td>\n",
       "      <td>2.967454e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34078</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.4588</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34079</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.033152e-02</td>\n",
       "      <td>3.944086e-02</td>\n",
       "      <td>1.609102e-02</td>\n",
       "      <td>1.304207e-02</td>\n",
       "      <td>1.068483e-02</td>\n",
       "      <td>2.149892e-02</td>\n",
       "      <td>5.759583e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>6.247752e-03</td>\n",
       "      <td>3.470283e-03</td>\n",
       "      <td>9.628476e-04</td>\n",
       "      <td>6.650818e-04</td>\n",
       "      <td>4.172307e-04</td>\n",
       "      <td>7.998477e-04</td>\n",
       "      <td>3.188832e-04</td>\n",
       "      <td>6.576810e-04</td>\n",
       "      <td>1.122466e-03</td>\n",
       "      <td>8.797068e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34080</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>6.755078e-01</td>\n",
       "      <td>9.693865e-03</td>\n",
       "      <td>3.593326e-03</td>\n",
       "      <td>2.485474e-03</td>\n",
       "      <td>2.695232e-03</td>\n",
       "      <td>1.664804e-03</td>\n",
       "      <td>1.136906e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>6.262553e-04</td>\n",
       "      <td>3.779877e-04</td>\n",
       "      <td>1.508980e-04</td>\n",
       "      <td>2.013908e-04</td>\n",
       "      <td>9.219208e-05</td>\n",
       "      <td>1.429136e-04</td>\n",
       "      <td>9.088718e-05</td>\n",
       "      <td>1.325760e-04</td>\n",
       "      <td>1.257210e-04</td>\n",
       "      <td>1.701701e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34081</th>\n",
       "      <td>3.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>9.375952e-02</td>\n",
       "      <td>3.673904e-02</td>\n",
       "      <td>1.820126e-02</td>\n",
       "      <td>1.435631e-02</td>\n",
       "      <td>1.033300e-02</td>\n",
       "      <td>1.439382e-02</td>\n",
       "      <td>8.372131e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.857429e-02</td>\n",
       "      <td>5.303981e-03</td>\n",
       "      <td>9.482998e-04</td>\n",
       "      <td>6.789687e-04</td>\n",
       "      <td>5.971529e-04</td>\n",
       "      <td>8.714197e-04</td>\n",
       "      <td>4.025079e-04</td>\n",
       "      <td>7.018386e-04</td>\n",
       "      <td>1.365523e-03</td>\n",
       "      <td>7.897477e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21674 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating  topic_id  sentiment  topic_prob_0  topic_prob_1  topic_prob_2  \\\n",
       "0         4.0         9     0.6918  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1         5.0         1     0.8357  1.407189e-01  8.188058e-02  2.226152e-02   \n",
       "3         1.0        16     0.4215  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "4         1.0         5    -0.8079  1.589250e-09  6.833651e-10  2.607126e-10   \n",
       "6         3.0         0     0.6369  9.524698e-01  3.504301e-16  3.650877e-17   \n",
       "...       ...       ...        ...           ...           ...           ...   \n",
       "34077     3.0         0     0.0000  9.320462e-01  1.771362e-02  6.868606e-03   \n",
       "34078     1.0         1    -0.4588  0.000000e+00  1.000000e+00  0.000000e+00   \n",
       "34079     1.0        14     0.0000  9.033152e-02  3.944086e-02  1.609102e-02   \n",
       "34080     1.0         0    -0.4215  6.755078e-01  9.693865e-03  3.593326e-03   \n",
       "34081     3.0        19     0.4215  9.375952e-02  3.673904e-02  1.820126e-02   \n",
       "\n",
       "       topic_prob_3  topic_prob_4  topic_prob_5  topic_prob_6  ...  \\\n",
       "0      0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
       "1      1.450290e-02  1.747066e-02  9.261023e-03  4.040478e-03  ...   \n",
       "3      0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
       "4      2.866307e-10  1.906143e-10  9.216001e-01  8.747127e-11  ...   \n",
       "6      2.437965e-17  6.270424e-17  1.292472e-17  6.621524e-18  ...   \n",
       "...             ...           ...           ...           ...  ...   \n",
       "34077  5.126198e-03  5.285674e-03  3.002853e-03  1.734204e-03  ...   \n",
       "34078  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
       "34079  1.304207e-02  1.068483e-02  2.149892e-02  5.759583e-03  ...   \n",
       "34080  2.485474e-03  2.695232e-03  1.664804e-03  1.136906e-03  ...   \n",
       "34081  1.435631e-02  1.033300e-02  1.439382e-02  8.372131e-03  ...   \n",
       "\n",
       "       topic_prob_19  topic_prob_20  topic_prob_21  topic_prob_22  \\\n",
       "0       0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "1       3.242651e-03   1.977243e-03   7.956023e-04   8.253871e-04   \n",
       "3       0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "4       2.242550e-10   9.370864e-11   2.350942e-11   1.147031e-11   \n",
       "6       5.188340e-18   3.170885e-18   1.203477e-18   1.355813e-18   \n",
       "...              ...            ...            ...            ...   \n",
       "34077   1.165273e-03   7.011363e-04   2.889388e-04   3.775342e-04   \n",
       "34078   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "34079   6.247752e-03   3.470283e-03   9.628476e-04   6.650818e-04   \n",
       "34080   6.262553e-04   3.779877e-04   1.508980e-04   2.013908e-04   \n",
       "34081   3.857429e-02   5.303981e-03   9.482998e-04   6.789687e-04   \n",
       "\n",
       "       topic_prob_23  topic_prob_24  topic_prob_25  topic_prob_26  \\\n",
       "0       0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "1       3.012792e-04   5.731639e-04   2.557884e-04   4.783740e-04   \n",
       "3       0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "4       5.396873e-12   1.180296e-11   3.979662e-12   8.465927e-12   \n",
       "6       4.641004e-19   8.230099e-19   4.265775e-19   6.832141e-19   \n",
       "...              ...            ...            ...            ...   \n",
       "34077   1.332665e-04   2.167131e-04   1.260888e-04   1.758986e-04   \n",
       "34078   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "34079   4.172307e-04   7.998477e-04   3.188832e-04   6.576810e-04   \n",
       "34080   9.219208e-05   1.429136e-04   9.088718e-05   1.325760e-04   \n",
       "34081   5.971529e-04   8.714197e-04   4.025079e-04   7.018386e-04   \n",
       "\n",
       "       topic_prob_27  topic_prob_28  \n",
       "0       0.000000e+00   0.000000e+00  \n",
       "1       6.327596e-04   1.348677e-03  \n",
       "3       0.000000e+00   0.000000e+00  \n",
       "4       2.193662e-11   1.530323e-11  \n",
       "6       1.038787e-18   1.314411e-18  \n",
       "...              ...            ...  \n",
       "34077   2.284043e-04   2.967454e-04  \n",
       "34078   0.000000e+00   0.000000e+00  \n",
       "34079   1.122466e-03   8.797068e-04  \n",
       "34080   1.257210e-04   1.701701e-04  \n",
       "34081   1.365523e-03   7.897477e-04  \n",
       "\n",
       "[21674 rows x 32 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fc9354",
   "metadata": {},
   "source": [
    "#### Training and Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f8bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_df.iloc[:, 2:] #topic probs and sentiment score\n",
    "y = model_df[\"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce439ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e525e35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.2935697432787452\n",
      "R-squared: 0.32440365479650346\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "r2 = r2_score(y_test, preds)\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703abf43",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace1aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": X.columns,\n",
    "    \"coefficient\": model.coef_\n",
    "}).sort_values(\"coefficient\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604eaa1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>topic_prob_25</td>\n",
       "      <td>1.572211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>1.528284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>topic_prob_8</td>\n",
       "      <td>1.196692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>topic_prob_12</td>\n",
       "      <td>1.097400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>topic_prob_23</td>\n",
       "      <td>1.041440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>topic_prob_6</td>\n",
       "      <td>0.661820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>topic_prob_7</td>\n",
       "      <td>0.583057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>topic_prob_10</td>\n",
       "      <td>0.514875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>topic_prob_19</td>\n",
       "      <td>0.384635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>topic_prob_26</td>\n",
       "      <td>0.145939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>topic_prob_21</td>\n",
       "      <td>-0.035872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>topic_prob_16</td>\n",
       "      <td>-0.064346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>topic_prob_3</td>\n",
       "      <td>-0.096452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>topic_prob_9</td>\n",
       "      <td>-0.128112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>topic_prob_15</td>\n",
       "      <td>-0.136360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>topic_prob_5</td>\n",
       "      <td>-0.165297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>topic_prob_0</td>\n",
       "      <td>-0.243148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>topic_prob_28</td>\n",
       "      <td>-0.259240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>topic_prob_22</td>\n",
       "      <td>-0.267140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>topic_prob_14</td>\n",
       "      <td>-0.272023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>topic_prob_1</td>\n",
       "      <td>-0.298872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>topic_prob_13</td>\n",
       "      <td>-0.318697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>topic_prob_4</td>\n",
       "      <td>-0.348178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>topic_prob_20</td>\n",
       "      <td>-0.392200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>topic_prob_2</td>\n",
       "      <td>-0.506439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>topic_prob_18</td>\n",
       "      <td>-0.509887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>topic_prob_11</td>\n",
       "      <td>-0.532145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>topic_prob_24</td>\n",
       "      <td>-0.801003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>topic_prob_27</td>\n",
       "      <td>-1.090452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>topic_prob_17</td>\n",
       "      <td>-1.141770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature  coefficient\n",
       "26  topic_prob_25     1.572211\n",
       "0       sentiment     1.528284\n",
       "9    topic_prob_8     1.196692\n",
       "13  topic_prob_12     1.097400\n",
       "24  topic_prob_23     1.041440\n",
       "7    topic_prob_6     0.661820\n",
       "8    topic_prob_7     0.583057\n",
       "11  topic_prob_10     0.514875\n",
       "20  topic_prob_19     0.384635\n",
       "27  topic_prob_26     0.145939\n",
       "22  topic_prob_21    -0.035872\n",
       "17  topic_prob_16    -0.064346\n",
       "4    topic_prob_3    -0.096452\n",
       "10   topic_prob_9    -0.128112\n",
       "16  topic_prob_15    -0.136360\n",
       "6    topic_prob_5    -0.165297\n",
       "1    topic_prob_0    -0.243148\n",
       "29  topic_prob_28    -0.259240\n",
       "23  topic_prob_22    -0.267140\n",
       "15  topic_prob_14    -0.272023\n",
       "2    topic_prob_1    -0.298872\n",
       "14  topic_prob_13    -0.318697\n",
       "5    topic_prob_4    -0.348178\n",
       "21  topic_prob_20    -0.392200\n",
       "3    topic_prob_2    -0.506439\n",
       "19  topic_prob_18    -0.509887\n",
       "12  topic_prob_11    -0.532145\n",
       "25  topic_prob_24    -0.801003\n",
       "28  topic_prob_27    -1.090452\n",
       "18  topic_prob_17    -1.141770"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1523095e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25_time___ affects rating by 1.572210727679721\n",
      "sentiment affects rating by 1.5282843678662026\n",
      "8_love_got_great_time affects rating by 1.1966917695964663\n",
      "12_product_item_great_good affects rating by 1.0973995892049186\n",
      "23_product_way__ affects rating by 1.0414396666116854\n",
      "6_ok_good_perfect_great affects rating by 0.6618196191638699\n",
      "7_color_material_ok_small affects rating by 0.5830567354080283\n",
      "10_cute_great_color_looks affects rating by 0.5148747172072277\n",
      "19_expected_wasnt_bad_ok affects rating by 0.3846348435117261\n",
      "26_bad_looks_little_quality affects rating by 0.14593904821042042\n",
      "21_day_right_product_work affects rating by -0.03587161518180883\n",
      "16_great_good_pretty_perfect affects rating by -0.06434630975246253\n",
      "3_cute_small_little_way affects rating by -0.09645232219952304\n",
      "9_work_day_dont_great affects rating by -0.12811173560014133\n",
      "15_looked_dont_did_didnt affects rating by -0.13636007019084562\n",
      "5_quality_bad_good_product affects rating by -0.16529747865495006\n",
      "0_fit_small_im_love affects rating by -0.2431475442796671\n",
      "28_doesnt_does_didnt_thought affects rating by -0.2592396761708596\n",
      "22_day_item_really_right affects rating by -0.2671400097299645\n",
      "14_price_looks_good_dont affects rating by -0.27202344605223067\n",
      "1_material_looks_bad_quality affects rating by -0.2988723416571018\n",
      "13_thought_cute_time_dont affects rating by -0.31869687982801986\n",
      "4_color_looks_love_disappointed affects rating by -0.3481781248336254\n",
      "20_work_return_didnt_item affects rating by -0.39219998057331684\n",
      "2_small_way_little_expected affects rating by -0.5064392514340211\n",
      "18_time_ok_disappointed_quality affects rating by -0.5098872392894035\n",
      "11_material_quality_bad_right affects rating by -0.5321445057644769\n",
      "24_time_return_thought_day affects rating by -0.8010028343982873\n",
      "27_dont___ affects rating by -1.0904522419362586\n",
      "17_time_day_disappointed_product affects rating by -1.1417700114510783\n"
     ]
    }
   ],
   "source": [
    "for i in coef_df.index:\n",
    "    if i != 0: #account for sentiment being 0 but not a topic\n",
    "        topic = topic_model.get_topic_info(i-1)['Name'].to_string(index=False)\n",
    "        coef = coef_df.loc[i,'coefficient']\n",
    "        print(f'{topic} affects rating by {coef}')\n",
    "    else:\n",
    "        topic = 'sentiment'\n",
    "        coef = coef_df.loc[i,'coefficient']\n",
    "        print(f'{topic} affects rating by {coef}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e77115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>25_time___</td>\n",
       "      <td>[time, , , , , , , , , ]</td>\n",
       "      <td>[nan, na at this time, nan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count        Name            Representation  \\\n",
       "0     25     21  25_time___  [time, , , , , , , , , ]   \n",
       "\n",
       "           Representative_Docs  \n",
       "0  [nan, na at this time, nan]  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info(25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
