{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de307d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\yzhen\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9a99bb",
   "metadata": {},
   "source": [
    "#### Cleaning Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df465c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30907, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('balanced_data.csv')\n",
    "\n",
    "tops = data[data['category'] == 'Shirts/Tops']\n",
    "\n",
    "tops['text'] = tops['text'].str.strip()\n",
    "tops = tops[tops['text'].str.split().str.len() >= 3]  # remove very short reviews\n",
    "bad_values = {\"na\", \"n a\", \"n/a\", \"none\", \"\"}\n",
    "tops = tops[~tops['text'].isin([\"na\", \"n a\", \"n/a\", \"none\", \"\"])] #remove bad values\n",
    "\n",
    "from langdetect import detect, DetectorFactory\n",
    "\n",
    "# fix randomness for reproducibility\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "def is_english(text):\n",
    "    \"\"\"Return True if the text is English, False otherwise.\"\"\"\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "tops['is_english'] = tops['text'].apply(is_english)\n",
    "\n",
    "tops = tops[tops['is_english']] #remove non-english reviews\n",
    "tops.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4467adf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30907"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = tops['text'].tolist()\n",
    "\n",
    "reviews = [r for r in reviews if r.lower() not in bad_values]\n",
    "\n",
    "reviews = [str(i) for i in reviews]\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)  # remove links\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)         # remove punctuation\n",
    "    text = re.sub(r\"\\d+\", \"\", text)             # remove numbers\n",
    "    text = text.encode(\"ascii\", \"ignore\").decode()  # remove emojis\n",
    "    return text\n",
    "\n",
    "reviews = [clean_text(r) for r in reviews]\n",
    "\n",
    "len(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8275c489",
   "metadata": {},
   "source": [
    "#### Topic Modeling BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f725f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_model = CountVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    min_df=20,            \n",
    "    max_df=0.8,           \n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    calculate_probabilities=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "303e53c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 19:18:59,871 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9872856121844c0aa9ac8a560ee5cf42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/966 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 19:20:56,869 - BERTopic - Embedding - Completed ✓\n",
      "2025-11-23 19:20:56,870 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-11-23 19:21:21,958 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-11-23 19:21:21,973 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-11-23 19:23:39,827 - BERTopic - Cluster - Completed ✓\n",
      "2025-11-23 19:23:39,854 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-11-23 19:23:40,816 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "topics, probs = topic_model.fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5092868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 19:23:41,941 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2025-11-23 19:23:42,046 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-11-23 19:23:42,770 - BERTopic - Representation - Completed ✓\n",
      "2025-11-23 19:23:42,770 - BERTopic - Topic reduction - Reduced number of topics from 306 to 30\n"
     ]
    }
   ],
   "source": [
    "topic_model = topic_model.reduce_topics(reviews, nr_topics=30) #cosolidate topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96516b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff0f141f9264097b2da0c7254176c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/966 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 19:25:38,694 - BERTopic - Dimensionality - Reducing dimensionality of input embeddings.\n",
      "2025-11-23 19:25:38,781 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-11-23 19:25:38,781 - BERTopic - Clustering - Approximating new points with `hdbscan_model`\n",
      "2025-11-23 19:25:39,764 - BERTopic - Probabilities - Start calculation of probabilities with HDBSCAN\n",
      "2025-11-23 19:30:07,275 - BERTopic - Probabilities - Completed ✓\n",
      "2025-11-23 19:30:07,276 - BERTopic - Cluster - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "topics, probs = topic_model.transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01e3cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "tops['topic'] = topics\n",
    "tops['topic_probs'] = probs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6968f7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30907, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tops.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5554c0fd",
   "metadata": {},
   "source": [
    "#### Sentiment Score with VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12f1c1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\yzhen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "tops['sentiment'] = tops['text'].apply(lambda x: sia.polarity_scores(str(x))[\"compound\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0804f34",
   "metadata": {},
   "source": [
    "#### Creating DataFrame with Probability Distribution for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b229b5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>topic_prob_0</th>\n",
       "      <th>topic_prob_1</th>\n",
       "      <th>topic_prob_2</th>\n",
       "      <th>topic_prob_3</th>\n",
       "      <th>topic_prob_4</th>\n",
       "      <th>topic_prob_5</th>\n",
       "      <th>topic_prob_6</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_prob_19</th>\n",
       "      <th>topic_prob_20</th>\n",
       "      <th>topic_prob_21</th>\n",
       "      <th>topic_prob_22</th>\n",
       "      <th>topic_prob_23</th>\n",
       "      <th>topic_prob_24</th>\n",
       "      <th>topic_prob_25</th>\n",
       "      <th>topic_prob_26</th>\n",
       "      <th>topic_prob_27</th>\n",
       "      <th>topic_prob_28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8357</td>\n",
       "      <td>0.235300</td>\n",
       "      <td>4.650442e-02</td>\n",
       "      <td>3.650306e-02</td>\n",
       "      <td>1.679372e-01</td>\n",
       "      <td>3.575584e-02</td>\n",
       "      <td>1.530364e-02</td>\n",
       "      <td>1.066822e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>9.842679e-04</td>\n",
       "      <td>4.895131e-03</td>\n",
       "      <td>6.082960e-04</td>\n",
       "      <td>1.136030e-03</td>\n",
       "      <td>7.398211e-04</td>\n",
       "      <td>7.129811e-04</td>\n",
       "      <td>9.065141e-04</td>\n",
       "      <td>1.247030e-03</td>\n",
       "      <td>1.651904e-03</td>\n",
       "      <td>1.636247e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>0.170790</td>\n",
       "      <td>2.533316e-02</td>\n",
       "      <td>2.670997e-02</td>\n",
       "      <td>2.041132e-02</td>\n",
       "      <td>1.492635e-02</td>\n",
       "      <td>9.030376e-03</td>\n",
       "      <td>5.922454e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>7.375602e-04</td>\n",
       "      <td>1.819878e-03</td>\n",
       "      <td>5.828516e-04</td>\n",
       "      <td>9.445351e-04</td>\n",
       "      <td>7.226641e-04</td>\n",
       "      <td>5.980123e-04</td>\n",
       "      <td>8.023744e-04</td>\n",
       "      <td>7.284924e-04</td>\n",
       "      <td>1.302170e-03</td>\n",
       "      <td>8.173486e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9150</td>\n",
       "      <td>0.107149</td>\n",
       "      <td>5.792131e-01</td>\n",
       "      <td>1.014467e-02</td>\n",
       "      <td>2.184771e-02</td>\n",
       "      <td>1.816267e-02</td>\n",
       "      <td>3.983197e-03</td>\n",
       "      <td>2.764112e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.705237e-04</td>\n",
       "      <td>9.995637e-04</td>\n",
       "      <td>1.826030e-04</td>\n",
       "      <td>3.732847e-04</td>\n",
       "      <td>2.463259e-04</td>\n",
       "      <td>2.100690e-04</td>\n",
       "      <td>2.982318e-04</td>\n",
       "      <td>3.295871e-04</td>\n",
       "      <td>4.930494e-04</td>\n",
       "      <td>3.642787e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30902</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.967487e-09</td>\n",
       "      <td>1.636042e-09</td>\n",
       "      <td>1.496203e-09</td>\n",
       "      <td>9.910888e-10</td>\n",
       "      <td>7.593174e-10</td>\n",
       "      <td>5.015099e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>7.352875e-11</td>\n",
       "      <td>1.480350e-10</td>\n",
       "      <td>5.904868e-11</td>\n",
       "      <td>1.019727e-10</td>\n",
       "      <td>1.633424e-10</td>\n",
       "      <td>5.516477e-11</td>\n",
       "      <td>1.168074e-10</td>\n",
       "      <td>6.114784e-11</td>\n",
       "      <td>6.419881e-11</td>\n",
       "      <td>6.623546e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30903</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.4588</td>\n",
       "      <td>0.357991</td>\n",
       "      <td>9.006978e-02</td>\n",
       "      <td>5.774870e-02</td>\n",
       "      <td>2.393977e-01</td>\n",
       "      <td>5.271012e-02</td>\n",
       "      <td>2.614224e-02</td>\n",
       "      <td>2.009556e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>2.113248e-03</td>\n",
       "      <td>6.951781e-03</td>\n",
       "      <td>1.741326e-03</td>\n",
       "      <td>2.604612e-03</td>\n",
       "      <td>2.016828e-03</td>\n",
       "      <td>1.895402e-03</td>\n",
       "      <td>2.395403e-03</td>\n",
       "      <td>2.342274e-03</td>\n",
       "      <td>2.427522e-03</td>\n",
       "      <td>2.705861e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30904</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.101207</td>\n",
       "      <td>1.946482e-02</td>\n",
       "      <td>2.019649e-02</td>\n",
       "      <td>2.342093e-02</td>\n",
       "      <td>1.224150e-02</td>\n",
       "      <td>1.061801e-02</td>\n",
       "      <td>3.238983e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>9.881662e-04</td>\n",
       "      <td>2.225914e-03</td>\n",
       "      <td>9.391871e-04</td>\n",
       "      <td>7.973846e-04</td>\n",
       "      <td>7.320764e-04</td>\n",
       "      <td>1.275978e-03</td>\n",
       "      <td>7.828115e-04</td>\n",
       "      <td>2.477447e-03</td>\n",
       "      <td>7.502202e-04</td>\n",
       "      <td>1.412698e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30905</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>8.629145e-01</td>\n",
       "      <td>2.139970e-06</td>\n",
       "      <td>2.242695e-06</td>\n",
       "      <td>1.355255e-06</td>\n",
       "      <td>9.754264e-07</td>\n",
       "      <td>6.730335e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>9.185833e-08</td>\n",
       "      <td>2.051024e-07</td>\n",
       "      <td>8.538584e-08</td>\n",
       "      <td>1.387654e-07</td>\n",
       "      <td>1.213709e-07</td>\n",
       "      <td>7.774757e-08</td>\n",
       "      <td>1.397541e-07</td>\n",
       "      <td>8.109060e-08</td>\n",
       "      <td>8.092358e-08</td>\n",
       "      <td>8.843149e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30906</th>\n",
       "      <td>3.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.095905</td>\n",
       "      <td>1.773431e-02</td>\n",
       "      <td>2.016024e-02</td>\n",
       "      <td>1.831631e-02</td>\n",
       "      <td>1.110488e-02</td>\n",
       "      <td>9.609666e-03</td>\n",
       "      <td>1.284591e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>9.972974e-04</td>\n",
       "      <td>1.852534e-03</td>\n",
       "      <td>1.027411e-03</td>\n",
       "      <td>7.366051e-04</td>\n",
       "      <td>7.290448e-04</td>\n",
       "      <td>1.500128e-03</td>\n",
       "      <td>7.493284e-04</td>\n",
       "      <td>2.107790e-03</td>\n",
       "      <td>7.378217e-04</td>\n",
       "      <td>1.152663e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19088 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating  topic_id  sentiment  topic_prob_0  topic_prob_1  topic_prob_2  \\\n",
       "0         4.0         0     0.6918      1.000000  0.000000e+00  0.000000e+00   \n",
       "1         5.0         3     0.8357      0.235300  4.650442e-02  3.650306e-02   \n",
       "3         1.0        14     0.4215      0.000000  0.000000e+00  0.000000e+00   \n",
       "6         4.0         0     0.0516      0.170790  2.533316e-02  2.670997e-02   \n",
       "8         5.0         1     0.9150      0.107149  5.792131e-01  1.014467e-02   \n",
       "...       ...       ...        ...           ...           ...           ...   \n",
       "30902     3.0         0     0.0000      1.000000  1.967487e-09  1.636042e-09   \n",
       "30903     1.0         3    -0.4588      0.357991  9.006978e-02  5.774870e-02   \n",
       "30904     1.0         6     0.0000      0.101207  1.946482e-02  2.019649e-02   \n",
       "30905     1.0         1    -0.4215      0.000013  8.629145e-01  2.139970e-06   \n",
       "30906     3.0        17     0.4215      0.095905  1.773431e-02  2.016024e-02   \n",
       "\n",
       "       topic_prob_3  topic_prob_4  topic_prob_5  topic_prob_6  ...  \\\n",
       "0      0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
       "1      1.679372e-01  3.575584e-02  1.530364e-02  1.066822e-02  ...   \n",
       "3      0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
       "6      2.041132e-02  1.492635e-02  9.030376e-03  5.922454e-03  ...   \n",
       "8      2.184771e-02  1.816267e-02  3.983197e-03  2.764112e-03  ...   \n",
       "...             ...           ...           ...           ...  ...   \n",
       "30902  1.496203e-09  9.910888e-10  7.593174e-10  5.015099e-10  ...   \n",
       "30903  2.393977e-01  5.271012e-02  2.614224e-02  2.009556e-02  ...   \n",
       "30904  2.342093e-02  1.224150e-02  1.061801e-02  3.238983e-02  ...   \n",
       "30905  2.242695e-06  1.355255e-06  9.754264e-07  6.730335e-07  ...   \n",
       "30906  1.831631e-02  1.110488e-02  9.609666e-03  1.284591e-02  ...   \n",
       "\n",
       "       topic_prob_19  topic_prob_20  topic_prob_21  topic_prob_22  \\\n",
       "0       0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "1       9.842679e-04   4.895131e-03   6.082960e-04   1.136030e-03   \n",
       "3       0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "6       7.375602e-04   1.819878e-03   5.828516e-04   9.445351e-04   \n",
       "8       2.705237e-04   9.995637e-04   1.826030e-04   3.732847e-04   \n",
       "...              ...            ...            ...            ...   \n",
       "30902   7.352875e-11   1.480350e-10   5.904868e-11   1.019727e-10   \n",
       "30903   2.113248e-03   6.951781e-03   1.741326e-03   2.604612e-03   \n",
       "30904   9.881662e-04   2.225914e-03   9.391871e-04   7.973846e-04   \n",
       "30905   9.185833e-08   2.051024e-07   8.538584e-08   1.387654e-07   \n",
       "30906   9.972974e-04   1.852534e-03   1.027411e-03   7.366051e-04   \n",
       "\n",
       "       topic_prob_23  topic_prob_24  topic_prob_25  topic_prob_26  \\\n",
       "0       0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "1       7.398211e-04   7.129811e-04   9.065141e-04   1.247030e-03   \n",
       "3       0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "6       7.226641e-04   5.980123e-04   8.023744e-04   7.284924e-04   \n",
       "8       2.463259e-04   2.100690e-04   2.982318e-04   3.295871e-04   \n",
       "...              ...            ...            ...            ...   \n",
       "30902   1.633424e-10   5.516477e-11   1.168074e-10   6.114784e-11   \n",
       "30903   2.016828e-03   1.895402e-03   2.395403e-03   2.342274e-03   \n",
       "30904   7.320764e-04   1.275978e-03   7.828115e-04   2.477447e-03   \n",
       "30905   1.213709e-07   7.774757e-08   1.397541e-07   8.109060e-08   \n",
       "30906   7.290448e-04   1.500128e-03   7.493284e-04   2.107790e-03   \n",
       "\n",
       "       topic_prob_27  topic_prob_28  \n",
       "0       0.000000e+00   0.000000e+00  \n",
       "1       1.651904e-03   1.636247e-03  \n",
       "3       0.000000e+00   0.000000e+00  \n",
       "6       1.302170e-03   8.173486e-04  \n",
       "8       4.930494e-04   3.642787e-04  \n",
       "...              ...            ...  \n",
       "30902   6.419881e-11   6.623546e-11  \n",
       "30903   2.427522e-03   2.705861e-03  \n",
       "30904   7.502202e-04   1.412698e-03  \n",
       "30905   8.092358e-08   8.843149e-08  \n",
       "30906   7.378217e-04   1.152663e-03  \n",
       "\n",
       "[19088 rows x 32 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['rating'] = tops['rating']\n",
    "df['topic_id'] = topics\n",
    "df['sentiment'] = tops['sentiment']\n",
    "\n",
    "probs_df = pd.DataFrame(\n",
    "    probs,\n",
    "    columns = [f\"topic_prob_{i}\" for i in range(probs.shape[1])]\n",
    ")\n",
    "\n",
    "topic_prob = pd.concat([df.reset_index(drop=True), probs_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "#remove topic = -1 because those are outliers and should be ignored\n",
    "model_df = topic_prob[topic_prob['topic_id'] != -1]\n",
    "\n",
    "model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbd9115",
   "metadata": {},
   "source": [
    "#### Training and Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9885a614",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_df.iloc[:, 2:] #topic probs and sentiment score\n",
    "y = model_df[\"rating\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67b37bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.3133649149456061\n",
      "R-squared: 0.29328045999982744\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "r2 = r2_score(y_test, preds)\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db44b9",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "895fa727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment: 0.4802\n",
      "0_ordered_size_fit_wear: 0.0497\n",
      "12_looking_definitely_comfortable_fit: 0.0289\n",
      "3_material_expected_looks_returned: 0.0273\n",
      "2_old_big_way_expected: 0.0268\n",
      "1_time_bad_day_work: 0.0263\n",
      "4_picture_looks_received_disappointed: 0.0236\n",
      "11_disappointed_use_going_received: 0.0221\n",
      "27_product_bit_know_look: 0.0219\n",
      "7_product_item_perfect_time: 0.0217\n",
      "23_received_time_doesnt_did: 0.0185\n",
      "10_old_bought_perfect_works: 0.0177\n",
      "9_bad_material_looks_expected: 0.0175\n",
      "5_cute_size_big_looks: 0.0174\n",
      "22_day_fine_look_received: 0.0167\n",
      "14_big_use_old_bit: 0.0155\n",
      "18_comfortable_better_returned_going: 0.0150\n",
      "15_material_returned_right_wear: 0.0141\n",
      "16_return_returned_time_day: 0.0137\n",
      "8_cute_day_time_look: 0.0136\n",
      "25_going_works_perfect_use: 0.0133\n",
      "20_picture_doesnt_wasnt_look: 0.0129\n",
      "6_picture_product_bad_worth: 0.0126\n",
      "24_worth_ok_better_does: 0.0116\n",
      "13_bought_look_use_day: 0.0113\n",
      "21_time_return_use_works: 0.0111\n",
      "28_comfortable_bad_ok_fine: 0.0102\n",
      "26_works_product_work_didnt: 0.0101\n",
      "19_recommend_day_use_old: 0.0097\n",
      "17_expected_wanted_ok_wasnt: 0.0091\n"
     ]
    }
   ],
   "source": [
    "importances = model.feature_importances_\n",
    "\n",
    "sentiment = ['sentiment'] #first feature\n",
    "\n",
    "n_topics = topic_model.get_topic_info().shape[0]-1\n",
    "\n",
    "probs_names = [\n",
    "    topic_model.get_topic_info().loc[i+1, 'Name']\n",
    "    for i in range(n_topics)\n",
    "]\n",
    "\n",
    "topic_names = sentiment + probs_names\n",
    "\n",
    "for name, imp in sorted(zip(topic_names, importances), key=lambda x: -x[1]):\n",
    "    print(f\"{name}: {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b05d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
